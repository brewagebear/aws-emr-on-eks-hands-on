# EMR Spark on EKS ì‹¤ìŠµ ê°€ì´ë“œ

## ğŸ“š ì‹¤ìŠµ ê°œìš”

ì´ ì‹¤ìŠµì—ì„œëŠ” AWSì˜ ë‹¤ìŒ ì„œë¹„ìŠ¤ë“¤ì„ ì‚¬ìš©í•˜ì—¬ í˜„ëŒ€ì ì¸ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤:

- **Amazon EKS**: Kubernetes ê´€ë¦¬í˜• ì„œë¹„ìŠ¤
- **EMR on EKS**: EKSì—ì„œ ì‹¤í–‰ë˜ëŠ” Apache Spark
- **Amazon S3**: ë°ì´í„° ì €ì¥ì†Œ
- **Spark Operator**: Kubernetesì—ì„œ Spark ì‘ì—… ê´€ë¦¬
- **Amazon Athena**: S3ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ SQLë¡œ ì¿¼ë¦¬

### ğŸ¯ í•™ìŠµ ëª©í‘œ

1. EKSì—ì„œ EMR Spark í´ëŸ¬ìŠ¤í„° êµ¬ì„±
2. Sparkë¥¼ ì´ìš©í•œ ë¡œê·¸ ë°ì´í„° ì§‘ê³„ ë° ë¶„ì„
3. í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì´í•´
4. Athenaë¥¼ í†µí•œ ë°ì´í„° ì¿¼ë¦¬ ë° ë¶„ì„

### ğŸ’° ì˜ˆìƒ ë¹„ìš©

**ì‹œê°„ë‹¹ ì˜ˆìƒ ë¹„ìš© (ì„œìš¸ ë¦¬ì „ ê¸°ì¤€)**
- EKS ì œì–´ í‰ë©´: $0.10
- EKS ì›Œì»¤ ë…¸ë“œ (t3.medium Spot x2): ~$0.03
- NAT Gateway: $0.059
- ê¸°íƒ€ (S3, CloudWatch): ~$0.01
- **ì´ ì‹œê°„ë‹¹: ~$0.68** (ì•½ â‚©900)

âš ï¸ **ì¤‘ìš”**: ì‹¤ìŠµ ì™„ë£Œ í›„ ë°˜ë“œì‹œ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ì—¬ ì¶”ê°€ ê³¼ê¸ˆì„ ë°©ì§€í•˜ì„¸ìš”!

## ğŸš€ ì‹¤ìŠµ ì‹œì‘í•˜ê¸°

### ì‚¬ì „ ì¤€ë¹„ì‚¬í•­

1. **AWS CLI ì„¤ì¹˜ ë° êµ¬ì„±**
```bash
# AWS CLI ì„¤ì¹˜ í™•ì¸
aws --version

# AWS ìê²© ì¦ëª… êµ¬ì„±
aws configure
```

2. **í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜**
```bash
# kubectl ì„¤ì¹˜ (1.28.3 ë²„ì „)
curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.28.3/2023-11-14/bin/linux/amd64/kubectl
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin

# eksctl ì„¤ì¹˜
curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin

# Helm ì„¤ì¹˜ (3.x ì´ìƒ)
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
```

### Step 1: ì¸í”„ë¼ ë°°í¬

1. **CloudFormation í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ**
```bash
# ì‹¤ìŠµ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir spark-on-eks-lab
cd spark-on-eks-lab

# CloudFormation í…œí”Œë¦¿ ì €ì¥
# (ìœ„ì—ì„œ ì œê³µëœ CloudFormation í…œí”Œë¦¿ì„ emr-spark-eks-infrastructure.yamlë¡œ ì €ì¥)
```

2. **ìŠ¤íƒ ë°°í¬ ì‹¤í–‰**
```bash
# ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x deploy.sh
./deploy.sh
```

â³ **ëŒ€ê¸° ì‹œê°„**: ì•½ 15-20ë¶„ (EKS í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹œê°„)

### Step 2: EKS ë° EMR Virtual Cluster ì„¤ì •

```bash
# ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x setup-emr-virtual-cluster.sh
./setup-emr-virtual-cluster.sh
```

### Step 3: Spark ì‘ì—… ì œì¶œ 

```bash 
python3 submit_spark_job.py 
```

### Step 4: ê²°ê³¼ í™•ì¸

1. **S3ì—ì„œ ê²°ê³¼ í™•ì¸**
```bash
# ì§‘ê³„ëœ ë°ì´í„° í™•ì¸
aws s3 ls s3://[DATA_BUCKET]/output/ --recursive

# ë¡œê·¸ ë°ì´í„° í™•ì¸
aws s3 ls s3://[LOGS_BUCKET]/aggregated-logs/ --recursive
```

2. **ê° ë¶„ì„ ê²°ê³¼ ì´í•´**
- `hourly_traffic/`: ì‹œê°„ëŒ€ë³„ íŠ¸ë˜í”½ íŒ¨í„´
- `status_code_analysis/`: HTTP ìƒíƒœ ì½”ë“œë³„ ë¶„ì„
- `url_analysis/`: URL ì—”ë“œí¬ì¸íŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„
- `top_ips/`: ìƒìœ„ íŠ¸ë˜í”½ IP ì£¼ì†Œ
- `method_analysis/`: HTTP ë©”ì†Œë“œë³„ ë¶„ì„
- `error_logs/`: ì—ëŸ¬ ë¡œê·¸ ìƒì„¸ ë¶„ì„

### Step 5: Athenaë¥¼ í†µí•œ ë°ì´í„° ì¿¼ë¦¬

```sql 
CREATE EXTERNAL TABLE IF NOT EXISTS analytics_summary (
  total_requests BIGINT,
  unique_ips BIGINT,
  unique_sessions BIGINT,
  avg_response_time DOUBLE,
  total_bytes_sent BIGINT
)
STORED AS PARQUET
LOCATION 's3://spark-on-eks-hands-on-data-${AccountID}/output/analysis_yyyymmddd_hhmmss/summary/';
```

```sql
SELECT * FROM analytics_summary;
```

## ğŸ” ì‹¤ìŠµ ë‚´ìš© ì‹¬í™” í•™ìŠµ

### 1. Spark ì‘ì—… ë¶„ì„

**ë¡œê·¸ ì§‘ê³„ ìŠ¤í¬ë¦½íŠ¸ ì£¼ìš” ê¸°ëŠ¥:**
```python
# ì‹œê°„ë³„ íŠ¸ë˜í”½ ë¶„ì„ ì˜ˆì‹œ
hourly_traffic = df.groupBy(
    window(col("timestamp"), "1 hour")
).agg(
    count("*").alias("request_count"),
    sum("bytes_sent").alias("total_bytes"),
    avg("response_time").alias("avg_response_time")
)
```

### 2. ë¹„ìš© ìµœì í™” í¬ì¸íŠ¸

**ì‹¤ìŠµì— ì ìš©ëœ ë¹„ìš© ì ˆì•½ ë°©ë²•:**
- Spot ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© (ìµœëŒ€ 90% í• ì¸)
- ìµœì†Œ ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… (t3.medium)
- ë‹¨ì¼ NAT Gateway
- ìë™ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ìœ íœ´ ë¦¬ì†ŒìŠ¤ ìµœì†Œí™”
- S3 Lifecycle ì •ì±…ìœ¼ë¡œ ì˜¤ë˜ëœ ë°ì´í„° ìë™ ì‚­ì œ

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

**1. EKS í´ëŸ¬ìŠ¤í„° ì ‘ê·¼ ë¶ˆê°€**
```bash
# kubeconfig ì—…ë°ì´íŠ¸
aws eks update-kubeconfig --region ap-northeast-2 --name spark-on-eks-demo-cluster

# ê¶Œí•œ í™•ì¸
kubectl auth can-i "*" "*"
```

**2. Spark ì‘ì—… ì‹¤íŒ¨**
```bash
# EMR ì‘ì—… ë¡œê·¸ í™•ì¸
aws emr-containers describe-job-run --virtual-cluster-id [CLUSTER_ID] --id [JOB_ID]

# CloudWatch ë¡œê·¸ í™•ì¸
aws logs describe-log-groups --log-group-name-prefix "/aws/emr-containers"
```

**3. S3 ê¶Œí•œ ì˜¤ë¥˜**
```bash
# IAM ì—­í•  ê¶Œí•œ í™•ì¸
aws iam get-role-policy --role-name spark-on-eks-demo-emr-execution-role --policy-name EMRExecutionPolicy
```

### ë””ë²„ê¹… íŒ

1. **CloudWatch Logs í™œìš©**
    - EMR ì»¨í…Œì´ë„ˆ ë¡œê·¸: `/aws/emr-containers/spark-on-eks-demo`
    - MWAA ë¡œê·¸: `/aws/airflow/spark-on-eks-demo-mwaa`

2. **Kubernetes ë””ë²„ê¹…**
```bash
# Pod ìƒíƒœ í™•ì¸
kubectl get pods -n emr
kubectl get pods -n spark-operator

# ìƒì„¸ ë¡œê·¸ í™•ì¸
kubectl logs -n emr [POD_NAME]
```

## ğŸ§ª ì¶”ê°€ ì‹¤í—˜

### ì‹¤í—˜ 1: ë‹¤ë¥¸ ë°ì´í„° ì†ŒìŠ¤ ì‚¬ìš©

CSV ëŒ€ì‹  JSON ë¡œê·¸ íŒŒì¼ì„ ì²˜ë¦¬í•˜ë„ë¡ Spark ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •:

```python
# JSON ë¡œê·¸ ì½ê¸°
df = spark.read.json(input_path)
```

### ì‹¤í—˜ 2: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬

Spark Structured Streamingì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ë¡œê·¸ ì²˜ë¦¬:

```python
# ìŠ¤íŠ¸ë¦¬ë° DataFrame ìƒì„±
streaming_df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .load()
```

### ì‹¤í—˜ 3: ë‹¤ì–‘í•œ ì§‘ê³„ í•¨ìˆ˜ ì¶”ê°€

```python
# ê³ ê¸‰ ì§‘ê³„ í•¨ìˆ˜
from pyspark.sql.functions import percentile_approx, collect_list

# ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°
response_time_percentiles = df.agg(
    percentile_approx("response_time", 0.5).alias("median"),
    percentile_approx("response_time", 0.95).alias("p95"),
    percentile_approx("response_time", 0.99).alias("p99")
)
```

## ğŸ§¹ ì •ë¦¬í•˜ê¸°

ì‹¤ìŠµ ì™„ë£Œ í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¼ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ì„¸ìš”:

### ìˆ˜ë™ ì •ë¦¬

1**Virtual Cluster ì‚­ì œ**
```bash
aws emr-containers delete-virtual-cluster --id [CLUSTER_ID]
```

2**CloudFormation ìŠ¤íƒ ì‚­ì œ**
```bash
aws cloudformation delete-stack --stack-name spark-on-eks-demo
```

3**S3 ë²„í‚· ë¹„ìš°ê¸°** (í•„ìš”ì‹œ)
```bash
aws s3 rm s3://[BUCKET_NAME] --recursive
```

## ğŸ“ ì‹¤ìŠµ ë³´ê³ ì„œ í…œí”Œë¦¿

ì‹¤ìŠµ ì™„ë£Œ í›„ ë‹¤ìŒ ì§ˆë¬¸ë“¤ì— ë‹µí•´ë³´ì„¸ìš”:

### ê¸°ìˆ ì  ì´í•´

1. **EMR on EKSì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?**
    - ê¸°ì¡´ EMR í´ëŸ¬ìŠ¤í„° ëŒ€ë¹„ ì¥ì 
    - Kubernetes ê¸°ë°˜ì˜ ì´ì 

2. **Spark ì‘ì—…ì—ì„œ ì–´ë–¤ ìµœì í™”ë¥¼ ì ìš©í–ˆë‚˜ìš”?**
    - íŒŒí‹°ì…˜ ì„¤ì •
    - ë©”ëª¨ë¦¬ êµ¬ì„±
    - ì••ì¶• ë°©ì‹

3. **MWAAë¥¼ ì‚¬ìš©í•œ ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì˜ ì´ì ì€?**
    - ê¸°ì¡´ cron job ëŒ€ë¹„ ì¥ì 
    - ì˜ì¡´ì„± ê´€ë¦¬
    - ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

### ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜

1. **ì´ íŒŒì´í”„ë¼ì¸ì´ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ì—ì„œ ì–´ë–»ê²Œ í™œìš©ë  ìˆ˜ ìˆë‚˜ìš”?**

2. **í™•ì¥ì„± ì¸¡ë©´ì—ì„œ ê³ ë ¤í•´ì•¼ í•  ì ë“¤ì€?**

3. **ë³´ì•ˆ ì¸¡ë©´ì—ì„œ ê°œì„ í•  ì ë“¤ì€?**

### ë¹„ìš© ìµœì í™”

1. **ì‹¤ìŠµì—ì„œ ì ìš©í•œ ë¹„ìš© ìµœì í™” ë°©ë²•ë“¤ì„ ì„¤ëª…í•˜ì„¸ìš”.**

2. **í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì¶”ê°€ë¡œ ê³ ë ¤í•  ë¹„ìš© ìµœì í™” ë°©ì•ˆì€?**

## ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

- [Amazon EMR on EKS ê°œë°œì ê°€ì´ë“œ](https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/)
- [Apache Spark ìµœì í™” ê°€ì´ë“œ](https://spark.apache.org/docs/latest/tuning.html)
- [Amazon MWAA ì‚¬ìš©ì ê°€ì´ë“œ](https://docs.aws.amazon.com/mwaa/latest/userguide/)
- [Kubernetes Spark Operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator)

---

**ì‹¤ìŠµ ë¬¸ì˜ì‚¬í•­ì´ë‚˜ ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ê°•ì‚¬ì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”!** ğŸ™‹â€â™‚ï¸


### íŠ¸ëŸ¬ë¸” ìŠˆíŒ…

#### Python ê°€ìƒë¨¸ì‹ 

```sh
â¯ python3 -m venv path/to/venv
â¯ source path/to/venv/bin/activate
â¯ pip3 install -r requirements.txt
```

#### OICD ì¸ì¦ ê´€ë ¨

```sh
eksctl utils associate-iam-oidc-provider \
  --cluster <EKS_CLUSTER_NAME> \
  --region ap-northeast-2 \
  --approve
```

```sh
kubectl run irsa-test --rm -it --restart=Never -n emr \
  --image=amazonlinux:2 \
  --overrides='
{
  "apiVersion": "v1",
  "kind": "Pod",
  "metadata": {
    "name": "irsa-test"
  },
  "spec": {
    "serviceAccountName": "irsa-test-sa",
    "containers": [{
      "name": "aws-cli",
      "image": "amazonlinux:2",
      "command": ["/bin/sh", "-c"],
      "args": ["yum install -y aws-cli && aws sts get-caller-identity"]
    }],
    "restartPolicy": "Never"
  }
}'
```

ìœ„ ì‰˜ìŠ¤í¬ë¦½íŠ¸ ê²°ê³¼ê°€ ì •ìƒì ì´ë©´ OICD ì¸ì¦ì´ ì œëŒ€ë¡œ ë™ì‘í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŒ

### ë¦¬ì†ŒìŠ¤ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨ ì‹œ

```
âŒ ì‘ì—… ì‹¤íŒ¨: FAILED
   ì„¸ë¶€ì‚¬í•­: JobRun timed out before spark driver pod started running due to lack of cluster resources. Last event from default-scheduler: FailedScheduling, message: 0/2 nodes are available: 1 Insufficient cpu, 2 Insufficient memory. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.. Please refer logs uploaded to S3/CloudWatch based on your monitoring configuration.
```

ìœ„ì™€ ê°™ì€ ì—ëŸ¬ê°€ ë°œìƒí•  ê²½ìš° K8S ë¦¬ì†ŒìŠ¤ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨ì´ë¯€ë¡œ, eks node ìˆ˜ ìì²´ë¥¼ ì¦ê°€ì‹œí‚¨ë‹¤.

```sh
aws eks update-nodegroup-config \
  --cluster-name <cluster-name> \
  --nodegroup-name <nodegroup-name> \
  --scaling-config minSize=2,maxSize=5,desiredSize=4 \
  --region ap-northeast-2
```